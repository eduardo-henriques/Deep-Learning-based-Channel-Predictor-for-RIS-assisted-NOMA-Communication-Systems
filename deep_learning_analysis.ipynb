{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edu_l\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\edu_l\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, TimeDistributed, Flatten, RepeatVector, InputLayer, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "\n",
    "    def nrmse(self):\n",
    "        mse = mean_squared_error(self.y_true, self.y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse / (self.y_true.max() - self.y_true.min())\n",
    "\n",
    "    def mase(self):\n",
    "        n = len(self.y_true)\n",
    "        d = np.abs(np.diff(self.y_true)).sum() / (n - 1)\n",
    "        errors = np.abs(self.y_true - self.y_pred)\n",
    "        return errors.mean() / d\n",
    "\n",
    "    def mape(self):\n",
    "        return np.mean(np.abs((self.y_true - self.y_pred) / self.y_true)) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratePlots:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "        \n",
    "    def plot_model_evaluation(self, y_test, y_pred):\n",
    "        if y_test.ndim == 4:\n",
    "            M = y_test.shape[2]\n",
    "            SNR_values = y_test.shape[3]  # Number of SNR values\n",
    "        else:\n",
    "            M = y_test.shape[2]  # Number of users\n",
    "            SNR_values = 1  # No SNR dimension\n",
    "        # Ensure y_test and y_pred are reshaped to (num_samples, time steps, users, features)\n",
    "        # Assuming the last dimension has the real and imaginary parts\n",
    "        # Here, reshape is needed only if y_test and y_pred don't already match this form\n",
    "        K = y_test.shape[0]\n",
    "        time_steps = range(K)\n",
    "\n",
    "        for user in range(M):\n",
    "            plt.figure(figsize=(20, 10))\n",
    "\n",
    "            # Extract the real and imaginary parts of the received signals for each user\n",
    "            amplitude_test = y_test[:, :, user, 0].reshape(-1)\n",
    "            amplitude_pred = y_pred[:, :, user, 0].reshape(-1)\n",
    "\n",
    "            # Calculate the amplitude of the received signals for each user\n",
    "            amplitude_test = (amplitude_test**2)\n",
    "            amplitude_pred = (amplitude_pred**2)\n",
    "\n",
    "            # Normalize the amplitudes\n",
    "            max_amplitude = np.max(amplitude_test)\n",
    "            normalized_amplitude_test = amplitude_test / max_amplitude\n",
    "            normalized_amplitude_pred = amplitude_pred / max_amplitude\n",
    "\n",
    "            # Plot the normalized received power for each user and SNR\n",
    "            plt.plot(time_steps, normalized_amplitude_test, label=f'User {user + 1} Test')\n",
    "            plt.plot(time_steps, normalized_amplitude_pred, '--', label=f'User {user + 1} Pred')\n",
    "\n",
    "            # Label the axes and create a title and legend\n",
    "            plt.xlabel('Time Step')\n",
    "            plt.ylabel(f'Cascaded channel at user {user + 1}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.ylim([0, 1.1 * max_amplitude])\n",
    "            plt.show()\n",
    "\n",
    "    def plot_training_history(self, history):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_model_metrics(self, y_test, y_pred):\n",
    "\n",
    "        y_pred_flat = y_pred.reshape(-1, 2)  # Flatten to 2D\n",
    "        y_test_flat = y_test.reshape(-1, 2)  # Flatten to 2D\n",
    "        # Calculate metrics\n",
    "        nrmse_val = Evaluation.nrmse(y_test, y_pred)\n",
    "        mase_val = Evaluation.mase(y_test, y_pred)\n",
    "        mape_val = Evaluation.mape(y_test, y_pred)\n",
    "        r2_val = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"NRMSE: {nrmse_val}\")\n",
    "        print(f\"MASE: {mase_val}\")\n",
    "        print(f\"MAPE: {mape_val}\")\n",
    "        print(f\"R2 Score: {r2_val}\")\n",
    "\n",
    "        # Metrics for plotting\n",
    "        metrics = ['NRMSE', 'MASE', 'MAPE', 'R2 Score']\n",
    "        values = [nrmse_val, mase_val, mape_val, r2_val]\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(metrics, values, color='skyblue')\n",
    "        plt.xlabel('Metrics')\n",
    "        plt.ylabel('Values')\n",
    "        plt.title('Model Evaluation Metrics')\n",
    "        plt.ylim([0, max(values) + 0.05 * max(values)])  # Adjust y-axis limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel:\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "        self.model = Sequential()\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        t_i = self.processor.t_i\n",
    "        M = self.processor.M\n",
    "        N_t = self.processor.N_t\n",
    "        N_r = self.processor.N_r\n",
    "        t_o = self.processor.t_o\n",
    "\n",
    "        self.model.add(InputLayer(input_shape=(t_i, M, 2*N_t*N_r)))\n",
    "        self.model.add(Conv2D(64, kernel_size=(3, 1), padding='same', activation='relu'))\n",
    "        self.model.add(Conv2D(64, kernel_size=(3, 1), padding='same', activation='relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(RepeatVector(t_o))\n",
    "        self.model.add(LSTM(16, activation='tanh', return_sequences=True))\n",
    "        self.model.add(LSTM(16, return_sequences=True))\n",
    "        self.model.add(TimeDistributed(Dense(4)))\n",
    "        self.model.add(Reshape((t_o, M, 2*N_t*N_r)))\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error', metrics=[keras.metrics.MeanSquaredError(), 'accuracy'])\n",
    "        self.model.summary()\n",
    "\n",
    "    def train_model(self, X_train, y_train, validation_split=0.1, epochs=50, batch_size=32):\n",
    "        #early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        return self.model.fit(X_train, y_train, validation_split=validation_split, epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    def predict_model(self, X_test):\n",
    "        return self.model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetProcessor:\n",
    "    def __init__(self, file_path, t_i, t_o, N_t, N_r):\n",
    "        self.file_path = file_path\n",
    "        self.t_i = t_i  # Number of input time steps\n",
    "        self.t_o = t_o  # Number of output time steps\n",
    "        self.N_t = N_t  # Number of transmit antennas\n",
    "        self.N_r = N_r  # Number of receive antennas\n",
    "        self.M = None\n",
    "        self.K = None\n",
    "        self.SNR = None\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load the .mat dataset\n",
    "        data = scipy.io.loadmat(self.file_path)\n",
    "        Y = data[\"Y\"]\n",
    "        G = data[\"G\"]\n",
    "        if Y.ndim == 4:\n",
    "            Y = np.transpose(Y, (2, 1, 3, 0))\n",
    "            self.SNR = Y.shape[2]\n",
    "        else:\n",
    "            Y = np.transpose(Y, (2, 1, 0))\n",
    "        if G.ndim == 4:\n",
    "            G = np.transpose(G, (2, 1, 3, 0))\n",
    "        else:\n",
    "            G = np.transpose(G, (2, 1, 0))\n",
    "        return Y, G\n",
    "    \n",
    "    def preprocess_data(self, Y, G):\n",
    "        self.K = Y.shape[0]  # Number of timesteps\n",
    "        self.M = Y.shape[1]  # Number of users\n",
    "        Sample = self.K - self.t_i - self.t_o + 1\n",
    "        print(Sample)\n",
    "\n",
    "        # Create sequences for input and output\n",
    "        X = np.array([Y[i:i+self.t_i] for i in range(Sample)])\n",
    "        y = np.array([G[i + self.t_i:i + self.t_i + self.t_o] for i in range(Sample)])\n",
    "        return X, y\n",
    "    \n",
    "    def normalize_data(self, X, y):\n",
    "        # Normalize data\n",
    "        scaler_X = MinMaxScaler()\n",
    "        X_scaled = scaler_X.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "\n",
    "        scaler_y = MinMaxScaler()\n",
    "        y_scaled = scaler_y.fit_transform(y.reshape(-1, y.shape[-1])).reshape(y.shape)\n",
    "        return X_scaled, y_scaled\n",
    "    \n",
    "    def split_data(self, X_scaled, y_scaled):\n",
    "        # Split the dataset\n",
    "        return train_test_split(X_scaled, y_scaled, test_size=0.3, random_state=42)\n",
    "\n",
    "    def reshape_for_cnn(self, X_train, X_test):\n",
    "        # Reshape for CNN input\n",
    "        t_i, M = X_train.shape[1], X_train.shape[2]\n",
    "        return (X_train.reshape((-1, t_i, M, 2*self.N_t*self.N_r)).astype('float32'),\n",
    "                X_test.reshape((-1, t_i, M, 2*self.N_t*self.N_r)).astype('float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19980\n",
      "(13986, 20, 2, 2) (5994, 20, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    processor = DatasetProcessor(\"dataset.mat\", 20, 1, 1, 1)\n",
    "    Y, G = processor.load_data()\n",
    "    \n",
    "    if Y.ndim == 4:\n",
    "        for snr_index in range(processor.SNR):\n",
    "            print(f\"Processing SNR index: {snr_index + 1}/{processor.SNR}\")\n",
    "            \n",
    "            Y_snr = Y[:, :, snr_index, :]\n",
    "            G_snr = G[:, :, snr_index, :]\n",
    "            \n",
    "            X, y = processor.preprocess_data(Y_snr, G_snr)\n",
    "            X_scaled, y_scaled = processor.normalize_data(X, y)\n",
    "            X_train, X_test, y_train, y_test = processor.split_data(X_scaled, y_scaled)\n",
    "            X_train, X_test = processor.reshape_for_cnn(X_train, X_test)\n",
    "        \n",
    "            model = CNNLSTMModel(processor)\n",
    "            history = model.train_model(X_train, y_train)\n",
    "            y_pred = model.predict_model(X_test)\n",
    "            plotter = GeneratePlots(processor)\n",
    "            plotter.plot_model_evaluation(y_test, y_pred)\n",
    "            plotter.plot_training_history(history)\n",
    "    else:\n",
    "        X, y = processor.preprocess_data(Y, G)\n",
    "        X_scaled, y_scaled = processor.normalize_data(X, y)\n",
    "        X_train, X_test, y_train, y_test = processor.split_data(X_scaled, y_scaled)\n",
    "        X_train, X_test = processor.reshape_for_cnn(X_train, X_test)\n",
    "    \n",
    "        print(X_train.shape, X_test.shape)\n",
    "        #model = CNNLSTMModel(processor)\n",
    "        #history = model.train_model(X_train, y_train)\n",
    "        #y_pred = model.predict_model(X_test)\n",
    "        #plotter = GeneratePlots(processor)\n",
    "        #plotter.plot_model_evaluation(y_test, y_pred)\n",
    "        #plotter.plot_training_history(history)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
